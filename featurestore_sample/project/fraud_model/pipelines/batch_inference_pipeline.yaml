# This is a pipeline is for illustration purpose only. Do not use it for production use.
description: batch inference pipeline
display_name: batch_inference
experiment_name: batch inference on fraud model
type: pipeline
settings:
  continue_on_step_failure: false

inputs:
  observation_data:
    mode: ro_mount
    path: wasbs://data@azuremlexampledata.blob.core.windows.net/feature-store-prp/observation_data/batch_inference/
    type: uri_folder
  timestamp_column: timestamp

jobs:

  model_retrieval_step:
    type: command
<<<<<<< HEAD
    compute: azureml:ml-test-cpu #ensure this matched the compute target in your workspace
=======
    compute: azureml:cpu-cluster-fs
>>>>>>> 5f413c9b73c4b38c1569fae9e8040806891ae5e1
    code: ../batch_inference/src
    environment: azureml:fs-env:1
    outputs:
      model_output:
        type: custom_model
    command: >-
      python fetch_model.py
      --model_output ${{outputs.model_output}}

  data_retrieval_step:
    component: azureml://registries/azureml/components/feature_retrieval/versions/1.1.1
    inputs:
      input_model:
        path: ${{parent.jobs.model_retrieval_step.outputs.model_output}}
      observation_data:
        path: ${{parent.inputs.observation_data}}
      timestamp_column: ${{parent.inputs.timestamp_column}}
      observation_data_format: parquet
    resources:
      instance_type: standard_e4s_v3
      runtime_version: "3.3"
    outputs:
      output_data:
    conf:
      spark.driver.cores: 4
      spark.driver.memory: 28g
      spark.executor.cores: 4
      spark.executor.memory: 28g
      spark.executor.instances: 2
    type: spark
  
  inference_step:
    type: command
<<<<<<< HEAD
    compute: azureml:ml-test-cpu #ensure this matched the compute target in your workspace
=======
    compute: azureml:cpu-cluster-fs
>>>>>>> 5f413c9b73c4b38c1569fae9e8040806891ae5e1
    code: ../batch_inference/src
    environment: azureml:fs-env:1
    inputs:
      model_input:
        path: ${{parent.jobs.model_retrieval_step.outputs.model_output}}
      inference_data:
        path: ${{parent.jobs.data_retrieval_step.outputs.output_data}}
    outputs:
      data_with_prediction:
        type: uri_folder
    command: >-
      python batch_inference.py
      --inference_data ${{inputs.inference_data}}
      --model_input ${{inputs.model_input}}
      --output_data ${{outputs.data_with_prediction}}